{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we will be importing our cleaned dataset and start building an ML model to predict the customer churn\n",
    "First set path\n",
    "'''\n",
    "path = r'F:\\Machine learning\\Machine learning practice\\Minimize Churn rate'\n",
    "#### Importing Libraries ####\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir(path)\n",
    "dataset = pd.read_csv('new_churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We are separating the user_ID field as this will not be input into the ML model.\n",
    "The field is stored for later use\n",
    "'''\n",
    "## Data Preparation\n",
    "user_identifier = dataset['user']\n",
    "dataset = dataset.drop(columns = ['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['churn', 'age', 'deposits', 'withdrawal', 'purchases_partners',\n",
       "       'purchases', 'cc_taken', 'cc_recommended', 'cc_disliked', 'cc_liked',\n",
       "       'cc_application_begin', 'app_downloaded', 'web_user', 'android_user',\n",
       "       'registered_phones', 'waiting_4_loan', 'cancelled_loan',\n",
       "       'received_loan', 'rejected_loan', 'left_for_two_month_plus',\n",
       "       'left_for_one_month', 'reward_rate', 'is_referred', 'housing_O',\n",
       "       'housing_R', 'housing_na', 'payment_type_Bi-Weekly',\n",
       "       'payment_type_Monthly', 'payment_type_Semi-Monthly',\n",
       "       'payment_type_Weekly', 'payment_type_na', 'zodiac_sign_Aquarius',\n",
       "       'zodiac_sign_Aries', 'zodiac_sign_Cancer', 'zodiac_sign_Capricorn',\n",
       "       'zodiac_sign_Gemini', 'zodiac_sign_Leo', 'zodiac_sign_Libra',\n",
       "       'zodiac_sign_Pisces', 'zodiac_sign_Sagittarius', 'zodiac_sign_Scorpio',\n",
       "       'zodiac_sign_Taurus', 'zodiac_sign_Virgo', 'zodiac_sign_na'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-Hot Encoding: This will introduce new columns for all the categorical columns. Very smart!!\n",
    "dataset = pd.get_dummies(dataset)\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prevent dummy variable trap\n",
    "dataset = dataset.drop(columns = ['housing_na', 'zodiac_sign_na', 'payment_type_na'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop(columns = 'churn'), dataset['churn'],\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before balancing churn column distribution:\n",
      "0    12656\n",
      "1     8940\n",
      "Name: churn, dtype: int64\n",
      "After balancing churn column distribution:\n",
      "1    8940\n",
      "0    8940\n",
      "Name: churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balancing the Training Set\n",
    "'''\n",
    "suppose the training set which was prepared is having data with around 60% churn = 0\n",
    "In our case we have data as such.\n",
    "Churn 1 was around 12K+ and churn 0 was around 8K+. This can create a bias\n",
    "Our model will be performing great even though the accuracy is 60%\n",
    "But there is some bias towards churn = 0. So our DS is pretty spread out.\n",
    "But in some case this doesn't happen after train test split.\n",
    "Thus it is needed to perform Training set balancing\n",
    "'''\n",
    "print('Before balancing churn column distribution:\\n' + str(y_train.value_counts()))\n",
    "\n",
    "pos_index = y_train[y_train.values == 1].index\n",
    "neg_index = y_train[y_train.values == 0].index\n",
    "\n",
    "'''\n",
    "Here we are balancing the positive and negative churns in the training set at random\n",
    "'''\n",
    "\n",
    "if len(pos_index) > len(neg_index):\n",
    "    higher = pos_index\n",
    "    lower = neg_index\n",
    "else:\n",
    "    higher = neg_index\n",
    "    lower = pos_index\n",
    "\n",
    "\n",
    "'''\n",
    "Length of churn 0 is more than length of churn 1.\n",
    "Thus we are chopping churn 0 to the length of churn 1\n",
    "'''\n",
    "random.seed(0)\n",
    "higher = np.random.choice(higher, size=len(lower))\n",
    "lower = np.asarray(lower)\n",
    "new_indexes = np.concatenate((lower, higher))\n",
    "\n",
    "X_train = X_train.loc[new_indexes,]\n",
    "y_train = y_train[new_indexes]\n",
    "\n",
    "'''\n",
    "Now churn 1 count = churn 0 count = 8940 nice!!!\n",
    "Run the code below\n",
    "'''\n",
    "print('After balancing churn column distribution:\\n' + str(y_train.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test))\n",
    "X_train2.columns = X_train.columns.values\n",
    "X_test2.columns = X_test.columns.values\n",
    "X_train2.index = X_train.index.values\n",
    "X_test2.index = X_test.index.values\n",
    "X_train = X_train2\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[1667 1499]\n",
      " [ 591 1643]]\n",
      "accuracy_score:0.6129629629629629\n",
      "precision_score:0.5229153405474221\n",
      "recall_score:0.7354521038495971\n",
      "f1_score:0.6112351190476191\n"
     ]
    }
   ],
   "source": [
    "#### Model Building ####\n",
    "\n",
    "\n",
    "# Fitting Model to the Training Set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "'''\n",
    "accuracy_score: Overall how many times our model predicted accurate = (tp+tn)/no. of obs\n",
    "precision_score: When it predicts yes, how often is it correct?\n",
    "'''\n",
    "# Evaluating Results\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix:\\n' + str(cm))\n",
    "print('accuracy_score:' + str(accuracy_score(y_test, y_pred)))\n",
    "print('precision_score:' + str(precision_score(y_test, y_pred))) # tp / (tp + fp)\n",
    "print('recall_score:' + str(recall_score(y_test, y_pred))) # tp / (tp + fn)\n",
    "print('f1_score:' + str(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
