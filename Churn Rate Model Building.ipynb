{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we will be importing our cleaned dataset and start building an ML model to predict the customer churn\n",
    "First set path\n",
    "'''\n",
    "path = r'C:\\Users\\Sandipto\\OneDrive\\Udemy ML\\Projects\\Churn model'\n",
    "#### Importing Libraries ####\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir(path)\n",
    "dataset = pd.read_csv('new_churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We are separating the user_ID field as this will not be input into the ML model.\n",
    "The field is stored for later use\n",
    "'''\n",
    "## Data Preparation\n",
    "user_identifier = dataset['user']\n",
    "dataset = dataset.drop(columns = ['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['churn', 'age', 'deposits', 'withdrawal', 'purchases_partners',\n",
       "       'purchases', 'cc_taken', 'cc_recommended', 'cc_disliked', 'cc_liked',\n",
       "       'cc_application_begin', 'app_downloaded', 'web_user', 'android_user',\n",
       "       'registered_phones', 'waiting_4_loan', 'cancelled_loan',\n",
       "       'received_loan', 'rejected_loan', 'left_for_two_month_plus',\n",
       "       'left_for_one_month', 'reward_rate', 'is_referred', 'housing_O',\n",
       "       'housing_R', 'housing_na', 'payment_type_Bi-Weekly',\n",
       "       'payment_type_Monthly', 'payment_type_Semi-Monthly',\n",
       "       'payment_type_Weekly', 'payment_type_na', 'zodiac_sign_Aquarius',\n",
       "       'zodiac_sign_Aries', 'zodiac_sign_Cancer', 'zodiac_sign_Capricorn',\n",
       "       'zodiac_sign_Gemini', 'zodiac_sign_Leo', 'zodiac_sign_Libra',\n",
       "       'zodiac_sign_Pisces', 'zodiac_sign_Sagittarius', 'zodiac_sign_Scorpio',\n",
       "       'zodiac_sign_Taurus', 'zodiac_sign_Virgo', 'zodiac_sign_na'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-Hot Encoding: This will introduce new columns for all the categorical columns. Very smart!!\n",
    "dataset = pd.get_dummies(dataset)\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prevent dummy variable trap\n",
    "dataset = dataset.drop(columns = ['housing_na', 'zodiac_sign_na', 'payment_type_na'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop(columns = 'churn'), dataset['churn'],\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before balancing churn column distribution:\n",
      "0    12656\n",
      "1     8940\n",
      "Name: churn, dtype: int64\n",
      "After balancing churn column distribution:\n",
      "1    8940\n",
      "0    8940\n",
      "Name: churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balancing the Training Set\n",
    "'''\n",
    "suppose the training set which was prepared is having data with around 60% churn = 0\n",
    "In our case we have data as such.\n",
    "Churn 1 was around 12K+ and churn 0 was around 8K+. This can create a bias\n",
    "Our model will be performing great even though the accuracy is 60%\n",
    "But there is some bias towards churn = 0. So our DS is pretty spread out.\n",
    "But in some case this doesn't happen after train test split.\n",
    "Thus it is needed to perform Training set balancing\n",
    "'''\n",
    "print('Before balancing churn column distribution:\\n' + str(y_train.value_counts()))\n",
    "\n",
    "pos_index = y_train[y_train.values == 1].index\n",
    "neg_index = y_train[y_train.values == 0].index\n",
    "\n",
    "'''\n",
    "Here we are balancing the positive and negative churns in the training set at random\n",
    "'''\n",
    "\n",
    "if len(pos_index) > len(neg_index):\n",
    "    higher = pos_index\n",
    "    lower = neg_index\n",
    "else:\n",
    "    higher = neg_index\n",
    "    lower = pos_index\n",
    "\n",
    "\n",
    "'''\n",
    "Length of churn 0 is more than length of churn 1.\n",
    "Thus we are chopping churn 0 to the length of churn 1\n",
    "'''\n",
    "random.seed(0)\n",
    "higher = np.random.choice(higher, size=len(lower))\n",
    "lower = np.asarray(lower)\n",
    "new_indexes = np.concatenate((lower, higher))\n",
    "\n",
    "X_train = X_train.loc[new_indexes,]\n",
    "y_train = y_train[new_indexes]\n",
    "\n",
    "'''\n",
    "Now churn 1 count = churn 0 count = 8940 nice!!!\n",
    "Run the code below\n",
    "'''\n",
    "print('After balancing churn column distribution:\\n' + str(y_train.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test))\n",
    "X_train2.columns = X_train.columns.values\n",
    "X_test2.columns = X_test.columns.values\n",
    "X_train2.index = X_train.index.values\n",
    "X_test2.index = X_test.index.values\n",
    "X_train = X_train2\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[1687 1479]\n",
      " [ 590 1644]]\n",
      "accuracy_score: 0.62\n",
      "precision_score: 0.53\n",
      "recall_score: 0.74\n",
      "f1_score: 0.61\n"
     ]
    }
   ],
   "source": [
    "#### Model Building ####\n",
    "\n",
    "\n",
    "# Fitting Model to the Training Set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(random_state = 0)\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "\n",
    "'''\n",
    "accuracy_score: Overall how many times our model predicted accurate = (tp+tn)/no. of obs\n",
    "precision_score: When it predicts yes, how often is it correct?\n",
    "'''\n",
    "# Evaluating Results\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix:\\n' + str(cm))\n",
    "print('accuracy_score: %.2f' %(accuracy_score(y_test, y_pred)))\n",
    "print('precision_score: %.2f' %(precision_score(y_test, y_pred))) # tp / (tp + fp)\n",
    "print('recall_score: %.2f' %(recall_score(y_test, y_pred))) # tp / (tp + fn)\n",
    "print('f1_score: %.2f' %(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel = 'linear', random_state = 0)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_kernel = SVC(kernel = 'rbf', random_state = 0)\n",
    "svc_kernel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "DT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(n_estimators = 250, criterion = 'entropy', random_state = 0)\n",
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias variance tradeoff:\n",
      "Accuracy average = 0.785234899328859\n",
      "Accuracy std = 0.008675216003128075\n"
     ]
    }
   ],
   "source": [
    "#perform k fold cross validation\n",
    "classifier = RF\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Bias variance tradeoff:\")\n",
    "print(\"Accuracy average = \" + str(accuracies.mean()))\n",
    "print(\"Accuracy std = \" + str(accuracies.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[1997 1169]\n",
      " [ 550 1684]]\n",
      "accuracy_score: 0.68\n",
      "precision_score: 0.59\n",
      "recall_score: 0.75\n",
      "f1_score: 0.66\n"
     ]
    }
   ],
   "source": [
    "#Performance evaluation of Random Forest on test set\n",
    "y_pred = RF.predict(X_test)\n",
    "\n",
    "\n",
    "'''\n",
    "accuracy_score: Overall how many times our model predicted accurate = (tp+tn)/no. of obs\n",
    "precision_score: When it predicts yes, how often is it correct?\n",
    "'''\n",
    "# Evaluating Results\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix:\\n' + str(cm))\n",
    "print('accuracy_score: %.2f'%(accuracy_score(y_test, y_pred)))\n",
    "print('precision_score: %.2f'%(precision_score(y_test, y_pred))) # tp / (tp + fp)\n",
    "print('recall_score: %.2f'%(recall_score(y_test, y_pred))) # tp / (tp + fn)\n",
    "print('f1_score: %.2f'%(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizing the Randomforest classifier using Gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'n_estimators':[100,150,200,250],\n",
    "               'criterion':['gini','entropy'],\n",
    "              }]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = ['f1','accuracy'],\n",
    "                           cv = 10,\n",
    "                           refit='f1',\n",
    "                           n_jobs = 1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1 and accuracy 0.7780440316929642\n",
      "best parameters {'criterion': 'entropy', 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "print('best f1 and accuracy ' + str(best_accuracy))\n",
    "print('best parameters ' + str(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing the CAP curve\n",
    "Y_pred_proba = RF.predict_proba(X_test)\n",
    "Y_cap = np.c_[y_test,Y_pred_proba[:, 1:]]\n",
    "dataframe = pd.DataFrame(data=Y_cap)\n",
    "dataframe.to_csv('courbeCAP.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5371</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5374</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5381</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5382</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5383</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5392</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1\n",
       "0     1.0  0.584\n",
       "1     0.0  0.352\n",
       "2     0.0  0.572\n",
       "3     0.0  0.576\n",
       "4     0.0  0.184\n",
       "5     0.0  0.408\n",
       "6     1.0  0.444\n",
       "7     1.0  0.692\n",
       "8     1.0  0.732\n",
       "9     0.0  0.516\n",
       "10    0.0  0.656\n",
       "11    0.0  0.224\n",
       "12    1.0  0.476\n",
       "13    0.0  0.556\n",
       "14    1.0  0.468\n",
       "15    1.0  0.864\n",
       "16    0.0  0.252\n",
       "17    0.0  0.472\n",
       "18    1.0  0.652\n",
       "19    0.0  0.128\n",
       "20    0.0  0.288\n",
       "21    0.0  0.456\n",
       "22    1.0  0.620\n",
       "23    1.0  0.560\n",
       "24    0.0  0.360\n",
       "25    1.0  0.492\n",
       "26    0.0  0.260\n",
       "27    1.0  0.620\n",
       "28    0.0  0.140\n",
       "29    1.0  0.760\n",
       "...   ...    ...\n",
       "5370  0.0  0.280\n",
       "5371  1.0  0.940\n",
       "5372  0.0  0.432\n",
       "5373  1.0  0.708\n",
       "5374  0.0  0.296\n",
       "5375  1.0  0.264\n",
       "5376  1.0  0.644\n",
       "5377  0.0  0.448\n",
       "5378  1.0  0.404\n",
       "5379  0.0  0.332\n",
       "5380  1.0  0.416\n",
       "5381  0.0  0.276\n",
       "5382  0.0  0.568\n",
       "5383  0.0  0.268\n",
       "5384  0.0  0.128\n",
       "5385  1.0  0.796\n",
       "5386  1.0  0.204\n",
       "5387  0.0  0.084\n",
       "5388  0.0  0.460\n",
       "5389  1.0  0.792\n",
       "5390  0.0  0.780\n",
       "5391  1.0  0.708\n",
       "5392  0.0  0.552\n",
       "5393  0.0  0.448\n",
       "5394  0.0  0.540\n",
       "5395  1.0  0.560\n",
       "5396  0.0  0.472\n",
       "5397  1.0  0.652\n",
       "5398  1.0  0.448\n",
       "5399  0.0  0.416\n",
       "\n",
       "[5400 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
